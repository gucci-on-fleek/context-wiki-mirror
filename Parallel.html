<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8">
  <link href="style.css" rel="stylesheet">
  <link href="favicon.ico" rel="icon" sizes="32x32">
  <title>
   Parallel&mdash;ConTeXt Wiki Mirror
  </title>
  <link href="https://wiki.contextgarden.net/Parallel" rel="canonical">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta content="#241504" name="theme-color">
  <meta content="light dark" name="color-scheme">
 </head>
 <body>
  <header>
   <h1 id="page-title">
    Parallel
   </h1>
   <p>Unofficial <a href="https://wiki.contextgarden.net/">ConTeXt Wiki</a> mirror</p>
   <p>Last modified: <a href="https://wiki.contextgarden.net/index.php?curid=2659&diff=28803">2020-06-08</a>
        </p>
  </header>
  <article>
   <div class="mw-parser-output">
    <p>Thanks, everybody, for the discussion on running TeX distributed / in parallel.
I am much educated about the state of the art.&nbsp;:-)
</p>
    <p>Summary ...
</p>
    <ul>
     <li>
      There is plenty of optimization that normally can be done, without having to parallelize. If a ConTeXt run is taking a really long time, chances are that something is not being done according to the design.
     </li>
    </ul>
    <ul>
     <li>
      For most (current) purposes, documents are small enough and ConTeXt is fast enough that the effort to automate distribution of typesetting runs may not be worthwhile. On the other hand, the usage of TeX might expand to larger applications if greater throughput were available.
     </li>
    </ul>
    <ul>
     <li>
      However, as things stand now, one can always divide documents up by hand, typeset the parts independently, and stitch them back together using tools such as divert/undivert. One can even design a document with the spec that the canonical typesetting process is to typeset the sections independently; then the sections can never affect each other, except for explicitly added inter-section effects like page reference updates.
     </li>
    </ul>
    <p>If you're not aware of MarkMail, it's a handy place to browse / search archives of mailing lists. This thread can be found at 
<a class="external free" href="http://markmail.org/search/?q=ntg+context+distributed+parallel" rel="nofollow">http://markmail.org/search/?q=ntg+context+distributed+parallel</a>
</p>
    <p>On 12/17/2008 2:47 AM, Taco Hoekwater wrote:
</p>
    <pre>&gt; There are some interesting ideas in this discussion, but with
&gt; the current state of the code base all of this will be exceedingly
&gt; difficult (especially because of all the synchronisation issues).
&gt; 
&gt; Unless someone wants to work on this idea him/herself (and that
&gt; would be great, there are not nearly enough people working on TeX
&gt; development!), you could remind me, say, two years from now?
</pre>
    <p>Sure. Thank you for your interest.
</p>
    <p>I wasn't asking for someone to implement new features for this, though I would be happy to see it happen if it is worthwhile for the community.
</p>
    <p>As Dr Dobb's says, "Single core systems are history" (<a class="external free" href="http://www.ddj.com/hpc-high-performance-computing/207100560" rel="nofollow">http://www.ddj.com/hpc-high-performance-computing/207100560</a>). Software that can take advantage of multiple cores (or threads, or distributed nodes) will continue to scale. Of course some effort, and often some adjustment, is necessary to enable programs to effectively use parallelism.
</p>
    <p>I'll create a page at <a class="external free" href="http://wiki.contextgarden.net/Parallel" rel="nofollow">http://wiki.contextgarden.net/Parallel</a> summarizing this discussion if that's OK.
</p>
    <p>Regards,
Lars
</p>
    <p>--<a class="new" href="index.php?title=User:Huttarl&action=edit&redlink=1" title="User:Huttarl (page does not exist)">Huttarl</a> 15:16, 17 December 2008 (CET)
</p>
    <!-- 
NewPP limit report
Cached time: 20260109212433
Cache expiry: 86400
Dynamic content: false
Complications: []
CPU time usage: 0.006 seconds
Real time usage: 0.008 seconds
Preprocessor visited node count: 4/1000000
Preprocessor generated node count: 0/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 434/5000000 bytes
-->
    <!--
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 -total
-->
    <!-- Saved in parser cache with key wikidb16_33:pcache:idhash:2659-1!canonical and timestamp 20260109212433 and revision id 28803
 -->
   </div>
  </article>
  <footer>
   <ul role="list">
    <li>
     <a href="index.html">
      Home
     </a>
    </li>
    <li>
     Mirrored on 2026-01-10
    </li>
    <li>
     <a href="http://www.gnu.org/copyleft/fdl.html" rel="license">
      GFDL 1.2
     </a>
    </li>
    <li>
     <a href="https://wiki.contextgarden.net/Parallel">
      Original page
     </a>
    </li>
   </ul>
  </footer>
 </body>
</html>
